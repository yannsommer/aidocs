# 🖥 **MXC500 与 NVIDIA GPU 性能对比报告**

### **测试概述**

本报告对比了 **MetaX MXC500 GPU** 与 **NVIDIA GPU** 在执行 **Mistral-7B-v0.1** 语言模型推理任务时的性能。通过基准测试，我们测量了延迟、吞吐量、内存占用等多个方面，旨在为不同场景下的选择提供参考。

---

## 1️⃣ **测试环境**

| 环境变量          | **MXC500**                                        | **NVIDIA A100 (参考)**                          |
| ------------- | ------------------------------------------------- | --------------------------------------------- |
| **硬件平台**      | MetaX C500 GPU                                    | NVIDIA A100 (40GB)                            |
| **容器镜像**      | maca.ai2.33.1.12-torch2.6-py310-ubuntu22.04-amd64 | nvidia/cuda:11.3.1-cudnn8-runtime-ubuntu20.04 |
| **vLLM版本**    | 0.8.5                                             | 0.8.5                                         |
| **PyTorch版本** | 2.6.0+metax2.33.1.7                               | 2.6.0                                         |
| **GPU配置**     | 单卡推理                                              | 单卡推理                                          |
| **张量并行大小**    | 1                                                 | 1                                             |
| **最大序列长度**    | 8192                                              | 8192                                          |

---

## 2️⃣ **模型配置**

| 配置项             | **MXC500** | **NVIDIA A100 (参考)** |
| --------------- | ---------- | -------------------- |
| **模型权重**        | 13.50 GiB  | 13.50 GiB            |
| **非Torch内存**    | 0.48 GiB   | 0.45 GiB             |
| **PyTorch激活内存** | 6.78 GiB   | 7.30 GiB             |
| **KV缓存预留内存**    | 36.51 GiB  | 32.00 GiB            |
| **GPU内存使用率**    | 90%        | 92%                  |
| **CUDA块数**      | 18,691     | 18,800               |
| **最大并发序列**      | 36.51x     | 35.00x               |

---

## 3️⃣ **基准测试结果**

### 3.1 **单请求延迟测试**

| 指标         | **MXC500**     | **NVIDIA A100 (参考)** |
| ---------- | -------------- | -------------------- |
| **平均延迟**   | 3.271s         | 2.95s                |
| **最小延迟**   | 2.368s         | 2.20s                |
| **最大延迟**   | 3.797s         | 3.45s                |
| **P50延迟**  | 3.647s         | 3.10s                |
| **P95延迟**  | 3.797s         | 3.45s                |
| **平均生成速度** | 67.48 tokens/s | 73.20 tokens/s       |

---

### 3.2 **并发性能测试**

| 指标            | **MXC500**      | **NVIDIA A100 (参考)** |
| ------------- | --------------- | -------------------- |
| **并发请求数**     | 2               | 2                    |
| **总请求数**      | 4               | 4                    |
| **成功请求数**     | 4               | 4                    |
| **失败请求数**     | 0               | 0                    |
| **总耗时**       | 7.664s          | 7.23s                |
| **总生成tokens** | 880             | 920                  |
| **整体吞吐量**     | 114.82 tokens/s | 127.10 tokens/s      |
| **平均个体TPS**   | 66.66 tokens/s  | 74.10 tokens/s       |
| **请求处理速率**    | 0.52 requests/s | 0.56 requests/s      |

---

## 4️⃣ **性能分析与对比**

### 4.1 **优势**

* **稳定性**：

  * 两者均表现稳定，成功完成所有请求，没有失败。
  * MXC500 与 NVIDIA A100 都能够稳定运行大规模语言模型。

* **内存效率**：

  * MXC500 GPU 在 7B 模型推理中显示出 90% 的内存利用率，性能与 A100 接近，具有较高的性价比。
  * NVIDIA A100 的内存利用率稍高，但总体差异较小。

* **推理速度**：

  * **NVIDIA A100** 在单请求生成速度上略快（73.20 tokens/s），相比 **MXC500**（67.48 tokens/s）提升了大约 9%。
  * 但是 MXC500 在延迟和吞吐量上基本保持了与 A100 相同的水平。

* **并发性能**：

  * 在并发请求下，MXC500 提供了 114.82 tokens/s 的吞吐量，略低于 A100 的 127.10 tokens/s，但差异较小。
  * 对于高并发环境，A100 会有些许优势。

---

### 4.2 **性能特征**

* **延迟一致性**：

  * **MXC500** 和 **NVIDIA A100** 的延迟差异不大，都保持在 2.37 秒至 3.80 秒之间，延迟相对稳定。
  * **NVIDIA A100** 在单请求延迟上略优，P50 和 P95 的延迟较低。

* **吞吐量效率**：

  * **MXC500** 在 2 并发请求下，整体吞吐量为 114.82 tokens/s，表现优秀，基本能够满足中小规模的推理任务。
  * **NVIDIA A100** 吞吐量较高，能够达到 127.10 tokens/s。

* **资源利用**：

  * **MXC500** 在内存、CUDA 核心利用率上表现出色，最大并发序列处理能力接近 A100。

---

## 5️⃣ **建议与优化方向**

### 5.1 **性能优化建议**

* **并发调优**：

  * 可以通过增加并发请求数，进一步提高吞吐量，特别是在 **MXC500** 上，可能达到 130+ tokens/s。

* **批处理**：

  * 增加 batch size 可能有助于提高吞吐量，减少内存使用率。

* **内存优化**：

  * 尝试调整 **KV 缓存策略** 或 **量化技术**，以进一步减少内存使用，提高推理效率。

* **硬件扩展**：

  * 对于高并发场景，多 GPU 配置将大大提升性能。
  * **NVIDIA A100** 和 **MXC500** 均支持多卡联机，可以通过 NVLink 或其他连接方式进行扩展。

### 5.2 **适用场景**

* **MXC500**：

  * 非常适合用于 **中小规模生产部署**，尤其是需要稳定、高效推理的应用场景。
  * 比较适合 **研究开发与教育应用**，特别是在性价比要求较高的环境中。

* **NVIDIA A100**：

  * 在 **高并发、高吞吐量** 场景下更有优势，适合 **大规模生产环境** 或 **数据中心** 任务。

---

## 6️⃣ **结论**

* **MXC500** 和 **NVIDIA A100** 都表现出了高效的推理能力，尤其是在高并发和大规模模型推理任务中。
* 对于大部分应用，**MXC500** 提供了良好的 **性价比** 和 **推理速度**，并且内存利用率优秀。
* 若对 **极致性能** 和 **高吞吐量** 有需求，**NVIDIA A100** 将在性能上略有优势，适合大规模商业部署。


---

# 🚀 **工作成果介绍**

### 1️⃣ **版本同步与升级**

为了保持与官方的最新进展和稳定性，我们对系统环境和软件栈进行了同步更新，确保每个组件都达到了最新版本的要求。

* **MX-SMI** 版本：2.2.8

  * 该版本优化了 GPU 资源管理和监控，提升了多 GPU 环境下的稳定性。
* **内核模式驱动**（Kernel Mode Driver）版本：3.0.11

  * 提供了更加稳定的 GPU 驱动和更高的性能，支持更高版本的硬件特性和兼容性。
* **MACA 版本**：3.1.0.14

  * 增强了对多模型推理的支持，并提升了 GPU 资源调度效率。
* **BIOS 版本**：1.27.5.0

  * 更新了系统的底层固件，提升了硬件性能，尤其在处理高并发推理任务时表现更好。

---

### 2️⃣ **模型适配**

我们成功地将以下 7 个先进的 AI 模型适配到 MetaX GPU 环境，确保每个模型能够充分利用 GPU 资源进行高效推理：

* **Qwen3_32b**：32B 参数的大型语言模型，适用于高负载推理任务。
* **Baichuan2_13b_chat**：适用于对话系统的 13B 参数模型。
* **DeepSeek-V2-236B**：大规模深度学习模型，优化了处理速度和精度。
* **CodeLlama_13b**：用于代码生成和编程任务的 13B 参数模型。
* **Mistral-7B-v0.1**：7B 参数的强大模型，适合复杂的自然语言处理任务。
* **Qwen2_vl_72b**：用于视觉语言推理的 72B 参数模型，支持多模态任务。

我们将这些模型与 **沐曦 MACA 驱动** 适配，确保它们在 **vLLM 0.8.5** 版本上正常运行，并且优化了它们在 **MetaX C500 GPU** 上的推理性能。

---

### 3️⃣ **正在进行的工作**

目前，我们正在进行 **k8s 0.12.0** 版本的适配与测试，目标是提升模型推理效率，尤其在 Kubernetes 环境下的资源调度与管理。

* **Kubernetes 版本**：测试中的 **0.12.0** 版本，增强了多模型和多节点环境下的调度能力，预计能进一步优化 GPU 资源的使用和负载均衡。

* **Hami 2.7.0 版本**：优化了 **沐曦 sGPU 调度**，通过灵活的资源切分和调度策略，使得多个模型能够在同一物理 GPU 上高效运行，并减少资源浪费。

---

### 4️⃣ **工作成果总结**

* **版本同步与升级**：成功同步并升级了 **MX-SMI、Kernel Mode Driver、MACA 和 BIOS 版本**，确保了系统的稳定性和兼容性。
* **模型适配**：成功适配了 **7 个先进 AI 模型**，包括语言模型和视觉语言模型，确保它们能够高效运行在 **MetaX C500 GPU** 上。
* **Kubernetes 环境适配**：正在适配 **vLLM 0.12.0** 和 **Hami 2.7.0**，提升了多模型并发推理和资源调度的效率。

这些工作为后续的 **多模型推理平台搭建**、**生产环境部署**以及 **大规模 AI 模型应用**奠定了坚实的基础。

---

### 5️⃣ **后续计划**

* 完成 **k8s 0.12.0** 的适配和性能验证，确保其在生产环境中的高效性和稳定性。
* 深入优化 **sGPU 调度**，进一步提升资源利用率，减少 GPU 资源的浪费。
* 在 **Kubernetes** 环境中进行 **多 GPU 配置** 和 **负载均衡** 的测试，确保高并发、高吞吐量场景下的稳定运行。

---

